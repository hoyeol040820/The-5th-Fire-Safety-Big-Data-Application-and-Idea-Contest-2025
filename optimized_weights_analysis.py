# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
from scipy.stats import pearsonr
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
import warnings
warnings.filterwarnings('ignore')

def optimize_weights_based_on_correlation():
    """
    ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì í™”ëœ ê°€ì¤‘ì¹˜ ì ìš©
    """
    print("ğŸ¯ ìƒê´€ê´€ê³„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ìµœì í™” ë¶„ì„ ì‹œì‘...")
    
    try:
        # 1. ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ë¡œë“œ
        merged_data = pd.read_csv('correlation_analysis_data.csv')
        print(f"âœ… ê¸°ì¡´ ë¶„ì„ ë°ì´í„° ë¡œë“œ: {len(merged_data)}ê°œ êµ¬")
        
        # 2. ê° êµ¬ì„±ìš”ì†Œë³„ ìƒê´€ê´€ê³„ ì¬ê³„ì‚°
        components = ['ì·¨ì•½ì—°ë ¹_í‰ê· ', 'ì·¨ì•½ì_í‰ê· ', 'ë…¸í›„ì£¼íƒ_í‰ê· ', 'êµ¬ì¡°ì¶œë™_í‰ê· ']
        component_names = ['ì·¨ì•½ì—°ë ¹ì¸µ', 'ì¬ë‚œì•ˆì „ì·¨ì•½ì', 'ë…¸í›„ì£¼íƒ', 'êµ¬ì¡°ì¶œë™']
        
        correlations = {}
        for comp, name in zip(components, component_names):
            corr, p_val = pearsonr(merged_data[comp], merged_data['ì¸ëª…í”¼í•´_ì •ê·œí™”'])
            correlations[name] = {'corr': corr, 'p_value': p_val, 'abs_corr': abs(corr)}
        
        print(f"\nğŸ“Š êµ¬ì„±ìš”ì†Œë³„ ìƒê´€ê´€ê³„:")
        for name, stats in correlations.items():
            print(f"â€¢ {name}: r={stats['corr']:+.3f}, p={stats['p_value']:.3f}")
        
        # 3. ë‹¤ì–‘í•œ ê°€ì¤‘ì¹˜ ìµœì í™” ë°©ë²• ì ìš©
        
        # ë°©ë²• 1: ì ˆëŒ“ê°’ ìƒê´€ê³„ìˆ˜ ë¹„ë¡€
        method1_weights = {}
        total_abs_corr = sum([stats['abs_corr'] for stats in correlations.values()])
        for name, stats in correlations.items():
            method1_weights[name] = stats['abs_corr'] / total_abs_corr
        
        # ë°©ë²• 2: ê²°ì •ê³„ìˆ˜(RÂ²) ê¸°ë°˜
        method2_weights = {}
        total_r_squared = sum([stats['corr']**2 for stats in correlations.values()])
        for name, stats in correlations.items():
            method2_weights[name] = (stats['corr']**2) / total_r_squared
        
        # ë°©ë²• 3: í†µê³„ì  ìœ ì˜ì„± ë°˜ì˜ (p<0.05ë©´ 2ë°°, p<0.1ë©´ 1.5ë°° ê°€ì¤‘)
        method3_weights = {}
        weighted_corrs = {}
        for name, stats in correlations.items():
            if stats['p_value'] < 0.05:
                weighted_corrs[name] = stats['abs_corr'] * 2.0  # ìœ ì˜í•¨
            elif stats['p_value'] < 0.1:
                weighted_corrs[name] = stats['abs_corr'] * 1.5  # ê±°ì˜ ìœ ì˜í•¨
            else:
                weighted_corrs[name] = stats['abs_corr'] * 1.0  # ì¼ë°˜
        
        total_weighted = sum(weighted_corrs.values())
        for name in weighted_corrs:
            method3_weights[name] = weighted_corrs[name] / total_weighted
        
        # ë°©ë²• 4: ì „ë¬¸ê°€ íŒë‹¨ + ë°ì´í„° ê¸°ë°˜ ì¡°í•© (ì¶”ì²œ)
        method4_weights = {
            'ë…¸í›„ì£¼íƒ': 0.45,        # ê°€ì¥ ê°•í•œ ìƒê´€ê´€ê³„ + ìœ ì˜í•¨
            'ì¬ë‚œì•ˆì „ì·¨ì•½ì': 0.25,   # ë‘ ë²ˆì§¸ ê°•í•œ ìƒê´€ê´€ê³„
            'ì·¨ì•½ì—°ë ¹ì¸µ': 0.20,      # ì„¸ ë²ˆì§¸ ìƒê´€ê´€ê³„
            'êµ¬ì¡°ì¶œë™': 0.10         # ì•½í•œ ìƒê´€ê´€ê³„ì´ì§€ë§Œ ì •ì±…ì  ì¤‘ìš”ì„±
        }
        
        # 4. ê°€ì¤‘ì¹˜ ë¹„êµí‘œ ì¶œë ¥
        print(f"\nğŸ“‹ ê°€ì¤‘ì¹˜ ìµœì í™” ê²°ê³¼ ë¹„êµ:")
        print(f"{'êµ¬ì„±ìš”ì†Œ':^12} | {'ê¸°ì¡´':^8} | {'ë°©ë²•1':^8} | {'ë°©ë²•2':^8} | {'ë°©ë²•3':^8} | {'ì¶”ì²œ':^8}")
        print("-" * 70)
        
        original_weights = {'ì·¨ì•½ì—°ë ¹ì¸µ': 0.30, 'ì¬ë‚œì•ˆì „ì·¨ì•½ì': 0.30, 'ë…¸í›„ì£¼íƒ': 0.20, 'êµ¬ì¡°ì¶œë™': 0.20}
        
        for name in component_names:
            print(f"{name:^12} | {original_weights[name]:^8.1%} | "
                  f"{method1_weights[name]:^8.1%} | {method2_weights[name]:^8.1%} | "
                  f"{method3_weights[name]:^8.1%} | {method4_weights[name]:^8.1%}")
        
        # 5. ìƒˆë¡œìš´ ê°€ì¤‘ì¹˜ë¡œ ì¢…í•©ìœ„í—˜ë„ ì¬ê³„ì‚°
        methods = {
            'ê¸°ì¡´': original_weights,
            'ìƒê´€ê³„ìˆ˜ë¹„ë¡€': method1_weights,
            'RÂ²ê¸°ë°˜': method2_weights,
            'ìœ ì˜ì„±ë°˜ì˜': method3_weights,
            'ë°ì´í„°ê¸°ë°˜ì¶”ì²œ': method4_weights
        }
        
        results_comparison = {}
        
        for method_name, weights in methods.items():
            # ìƒˆë¡œìš´ ì¢…í•©ìœ„í—˜ë„ ê³„ì‚°
            new_comprehensive = (
                merged_data['ì·¨ì•½ì—°ë ¹_í‰ê· '] * weights['ì·¨ì•½ì—°ë ¹ì¸µ'] +
                merged_data['ì·¨ì•½ì_í‰ê· '] * weights['ì¬ë‚œì•ˆì „ì·¨ì•½ì'] +
                merged_data['ë…¸í›„ì£¼íƒ_í‰ê· '] * weights['ë…¸í›„ì£¼íƒ'] +
                merged_data['êµ¬ì¡°ì¶œë™_í‰ê· '] * weights['êµ¬ì¡°ì¶œë™']
            )
            
            # ìƒˆë¡œìš´ ìƒê´€ê´€ê³„ ê³„ì‚°
            new_corr, new_p = pearsonr(new_comprehensive, merged_data['ì¸ëª…í”¼í•´_ì •ê·œí™”'])
            results_comparison[method_name] = {
                'correlation': new_corr,
                'p_value': new_p,
                'weights': weights
            }
        
        # 6. ê²°ê³¼ ë¹„êµ
        print(f"\nğŸ“ˆ ê°€ì¤‘ì¹˜ë³„ ìƒê´€ê´€ê³„ ê°œì„  íš¨ê³¼:")
        print(f"{'ë°©ë²•':^15} | {'ìƒê´€ê³„ìˆ˜':^10} | {'p-value':^10} | {'ê°œì„ ë„':^8}")
        print("-" * 50)
        
        baseline_corr = results_comparison['ê¸°ì¡´']['correlation']
        
        for method, result in results_comparison.items():
            improvement = result['correlation'] - baseline_corr
            print(f"{method:^15} | {result['correlation']:^10.3f} | "
                  f"{result['p_value']:^10.3f} | {improvement:^+8.3f}")
        
        # 7. ìµœì  ê°€ì¤‘ì¹˜ ì„ íƒ ë° ì ìš©
        best_method = max(results_comparison.items(), key=lambda x: x[1]['correlation'])
        print(f"\nğŸ† ìµœì  ê°€ì¤‘ì¹˜ ë°©ë²•: {best_method[0]}")
        print(f"   ìƒê´€ê³„ìˆ˜: {best_method[1]['correlation']:.3f}")
        print(f"   p-value: {best_method[1]['p_value']:.3f}")
        
        # 8. ìµœì  ê°€ì¤‘ì¹˜ë¡œ ìƒˆë¡œìš´ ì¢…í•©ìœ„í—˜ë„ ê³„ì‚°
        optimal_weights = best_method[1]['weights']
        merged_data['ìµœì _ì¢…í•©ìœ„í—˜ë„'] = (
            merged_data['ì·¨ì•½ì—°ë ¹_í‰ê· '] * optimal_weights['ì·¨ì•½ì—°ë ¹ì¸µ'] +
            merged_data['ì·¨ì•½ì_í‰ê· '] * optimal_weights['ì¬ë‚œì•ˆì „ì·¨ì•½ì'] +
            merged_data['ë…¸í›„ì£¼íƒ_í‰ê· '] * optimal_weights['ë…¸í›„ì£¼íƒ'] +
            merged_data['êµ¬ì¡°ì¶œë™_í‰ê· '] * optimal_weights['êµ¬ì¡°ì¶œë™']
        )
        
        # 9. ì‹œê°í™”
        print(f"\nğŸ“Š ìµœì í™” ê²°ê³¼ ì‹œê°í™” ì¤‘...")
        
        # Mac í•œê¸€ í°íŠ¸ ì„¤ì •
        import platform
        import matplotlib.font_manager as fm
        
        if platform.system() == 'Darwin':
            available_fonts = [font.name for font in fm.fontManager.ttflist]
            korean_fonts = ['AppleGothic', 'AppleMyungjo', 'NanumGothic', 'NanumMyeongjo']
            
            selected_font = None
            for font in korean_fonts:
                if font in available_fonts:
                    selected_font = font
                    break
            
            if selected_font:
                plt.rcParams['font.family'] = selected_font
            else:
                plt.rcParams['font.family'] = 'AppleGothic'
        
        plt.rcParams['axes.unicode_minus'] = False
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # ê¸°ì¡´ vs ìµœì í™” ê°€ì¤‘ì¹˜ ë¹„êµ
        ax1.scatter(merged_data['ì¢…í•©ìœ„í—˜ë„_í‰ê· '], merged_data['ì¸ëª…í”¼í•´_ì •ê·œí™”'], 
                   alpha=0.6, s=60, color='blue', label='ê¸°ì¡´ ê°€ì¤‘ì¹˜')
        ax1.scatter(merged_data['ìµœì _ì¢…í•©ìœ„í—˜ë„'], merged_data['ì¸ëª…í”¼í•´_ì •ê·œí™”'], 
                   alpha=0.6, s=60, color='red', label='ìµœì  ê°€ì¤‘ì¹˜')
        ax1.set_xlabel('ì¢…í•©ìœ„í—˜ë„ ì ìˆ˜')
        ax1.set_ylabel('í™”ì¬ì¸ëª…í”¼í•´ (ì •ê·œí™”)')
        ax1.set_title(f'ê°€ì¤‘ì¹˜ ìµœì í™” ì „í›„ ë¹„êµ\nê¸°ì¡´ r={baseline_corr:.3f} â†’ ìµœì  r={best_method[1]["correlation"]:.3f}')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # ê°€ì¤‘ì¹˜ ë¹„êµ ë§‰ëŒ€ê·¸ë˜í”„
        components_kr = ['ì·¨ì•½ì—°ë ¹ì¸µ', 'ì¬ë‚œì•ˆì „ì·¨ì•½ì', 'ë…¸í›„ì£¼íƒ', 'êµ¬ì¡°ì¶œë™']
        x = np.arange(len(components_kr))
        width = 0.35
        
        original_values = [original_weights[comp] for comp in components_kr]
        optimal_values = [optimal_weights[comp] for comp in components_kr]
        
        ax2.bar(x - width/2, original_values, width, label='ê¸°ì¡´ ê°€ì¤‘ì¹˜', alpha=0.7, color='skyblue')
        ax2.bar(x + width/2, optimal_values, width, label='ìµœì  ê°€ì¤‘ì¹˜', alpha=0.7, color='salmon')
        ax2.set_xlabel('êµ¬ì„±ìš”ì†Œ')
        ax2.set_ylabel('ê°€ì¤‘ì¹˜')
        ax2.set_title('ê°€ì¤‘ì¹˜ ìµœì í™” ì „í›„ ë¹„êµ')
        ax2.set_xticks(x)
        ax2.set_xticklabels(components_kr, rotation=45)
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # êµ¬ë³„ ìˆœìœ„ ë³€í™”
        merged_data['ê¸°ì¡´_ìˆœìœ„'] = merged_data['ì¢…í•©ìœ„í—˜ë„_í‰ê· '].rank(ascending=False)
        merged_data['ìµœì _ìˆœìœ„'] = merged_data['ìµœì _ì¢…í•©ìœ„í—˜ë„'].rank(ascending=False)
        merged_data['ìˆœìœ„_ë³€í™”'] = merged_data['ê¸°ì¡´_ìˆœìœ„'] - merged_data['ìµœì _ìˆœìœ„']
        
        colors = ['red' if x > 0 else 'blue' for x in merged_data['ìˆœìœ„_ë³€í™”']]
        ax3.barh(range(len(merged_data)), merged_data['ìˆœìœ„_ë³€í™”'], color=colors, alpha=0.7)
        ax3.set_yticks(range(len(merged_data)))
        ax3.set_yticklabels([gu.replace('êµ¬', '') for gu in merged_data['êµ¬ëª…']], fontsize=8)
        ax3.set_xlabel('ìˆœìœ„ ë³€í™” (ìƒìŠ¹: ë¹¨ê°•, í•˜ë½: íŒŒë‘)')
        ax3.set_title('êµ¬ë³„ ìœ„í—˜ë„ ìˆœìœ„ ë³€í™”')
        ax3.grid(True, alpha=0.3)
        ax3.axvline(x=0, color='black', linewidth=0.8)
        
        # ìƒê´€ê´€ê³„ ê°œì„  íš¨ê³¼
        methods_names = list(results_comparison.keys())
        correlations_values = [results_comparison[method]['correlation'] for method in methods_names]
        colors_bar = ['red' if method == best_method[0] else 'lightblue' for method in methods_names]
        
        ax4.bar(range(len(methods_names)), correlations_values, color=colors_bar, alpha=0.7)
        ax4.set_xticks(range(len(methods_names)))
        ax4.set_xticklabels(methods_names, rotation=45)
        ax4.set_ylabel('ìƒê´€ê³„ìˆ˜')
        ax4.set_title('ê°€ì¤‘ì¹˜ ë°©ë²•ë³„ ìƒê´€ê´€ê³„ ì„±ëŠ¥')
        ax4.grid(True, alpha=0.3)
        ax4.axhline(y=baseline_corr, color='red', linestyle='--', alpha=0.7, label='ê¸°ì¡´ ì„±ëŠ¥')
        ax4.legend()
        
        fig.suptitle('ìƒê´€ê´€ê³„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ìµœì í™” ë¶„ì„ ê²°ê³¼', fontsize=16, y=0.98)
        plt.tight_layout()
        plt.subplots_adjust(top=0.93)
        plt.savefig('optimized_weights_analysis.png', dpi=300, bbox_inches='tight')
        print(f"âœ… ì‹œê°í™” ì €ì¥: optimized_weights_analysis.png")
        
        # 10. ìµœì¢… ê²°ê³¼ ìš”ì•½
        print(f"\nğŸ¯ ê°€ì¤‘ì¹˜ ìµœì í™” ê²°ê³¼ ìš”ì•½:")
        print("=" * 60)
        print(f"ğŸ“ˆ ìƒê´€ê´€ê³„ ê°œì„ : {baseline_corr:.3f} â†’ {best_method[1]['correlation']:.3f} "
              f"(+{best_method[1]['correlation'] - baseline_corr:.3f})")
        print(f"ğŸ“Š ìµœì  ê°€ì¤‘ì¹˜:")
        for comp, weight in optimal_weights.items():
            print(f"   â€¢ {comp}: {weight:.1%}")
        
        print(f"\nğŸ” ìµœì í™” í›„ ìœ„í—˜ë„ ìƒìœ„ 10ê°œ êµ¬:")
        top_optimized = merged_data.nlargest(10, 'ìµœì _ì¢…í•©ìœ„í—˜ë„')[
            ['êµ¬ëª…', 'ìµœì _ì¢…í•©ìœ„í—˜ë„', 'ì¸ëª…í”¼í•´_ì†Œê³„', 'ìˆœìœ„_ë³€í™”']
        ]
        for idx, row in top_optimized.iterrows():
            change_str = f"(ìˆœìœ„ {'+' if row['ìˆœìœ„_ë³€í™”'] > 0 else ''}{row['ìˆœìœ„_ë³€í™”']:.0f})" if row['ìˆœìœ„_ë³€í™”'] != 0 else ""
            print(f"   {row['êµ¬ëª…']}: {row['ìµœì _ì¢…í•©ìœ„í—˜ë„']:.3f}, "
                  f"ì¸ëª…í”¼í•´={row['ì¸ëª…í”¼í•´_ì†Œê³„']:.0f}ëª… {change_str}")
        
        # ë°ì´í„° ì €ì¥
        merged_data.to_csv('optimized_weights_result.csv', index=False, encoding='utf-8-sig')
        print(f"\nâœ… ìµœì í™” ê²°ê³¼ ì €ì¥: optimized_weights_result.csv")
        
        return merged_data, optimal_weights, best_method[1]['correlation']
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        return None, None, None

if __name__ == "__main__":
    print("ğŸ¯ ìƒê´€ê´€ê³„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ìµœì í™”")
    print("=" * 60)
    
    result_data, optimal_weights, improved_corr = optimize_weights_based_on_correlation()
    
    if result_data is not None:
        print(f"\nğŸ‰ ê°€ì¤‘ì¹˜ ìµœì í™” ì™„ë£Œ!")
        print(f"ğŸ“Š ê°œì„ ëœ ìƒê´€ê³„ìˆ˜: {improved_corr:.4f}")
        print(f"ğŸ¯ ìµœì  ê°€ì¤‘ì¹˜: {optimal_weights}")
    else:
        print(f"\nğŸ’¥ ìµœì í™” ì‹¤íŒ¨!") 